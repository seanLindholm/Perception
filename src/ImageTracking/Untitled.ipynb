{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58, 6400)\n",
      "(58,)\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2]\n",
      "{1: 'book', 0: 'mug', 2: 'box'}\n",
      "The training score -rbf: 0.98\n",
      "The test score -rbf: 0.93\n"
     ]
    }
   ],
   "source": [
    "# This is the begining of a class which will define the model, \n",
    "# and be used for tracking cups, books and boxes on a convaier belt. \n",
    "# The model is build using Support Vector Machines (SVM), \n",
    "# since this is the method covered doing the class 313932.\n",
    "# Good site for building it all https://rpubs.com/Sharon_1684/454441\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "import logging\n",
    "import cv2\n",
    "\n",
    "\n",
    "class TrackObjects:\n",
    "\n",
    "    def __init__(self,dataset='dataset.csv',load_model = False):\n",
    "        # TODO: find a way to save the trained model, such that it is possible to call this class\n",
    "        # And get a pre trained model, such that we don't need to retrain it, all the time\n",
    "        self.dataframe = pd.read_csv(dataset,sep=',',encoding='utf8')\n",
    "\n",
    "    def createTrainingData(self):\n",
    "        # This function should loop over each image in the dataset and convert\n",
    "        # this into a readable flatten array. But to keep the feature mappings\n",
    "        # consistent accros all images, we need to do some resizing and grayscaling\n",
    "        # This log is just for convinience, since some pictures might not get loaded correctly\n",
    "        # which doesn't have to stop the process, but can be told to the user.\n",
    "        logging.basicConfig(filename=\"trainingDataGeneration.log\", \n",
    "                            level=logging.INFO,\n",
    "                            filemode='w',\n",
    "                            format='%(asctime)s %(levelname)-8s %(message)s',\n",
    "                            datefmt='%d-%m-%Y %H:%M:%S')\n",
    "        logging.info(\"Strating to generate training data\")\n",
    "        error_count = data_count = 0\n",
    "        self.target = []\n",
    "        self.dataset = []\n",
    "        categoryname = []\n",
    "        for path,cat,label in zip(self.dataframe[\"imagepath\"],self.dataframe[\"category\"],self.dataframe[\"label\"]):\n",
    "            # Get image from the path in the dataset.csv\n",
    "            img,res = self.__getimage(path)\n",
    "            if res == 0:\n",
    "                logging.error(\"The image on path {} with category {} could not be read\".format(path,cat))\n",
    "                error_count += 1\n",
    "            else:\n",
    "                self.dataset.append(self.__makefeatures(img))\n",
    "                data_count += 1\n",
    "                self.target.append(label)\n",
    "                categoryname.append(cat)\n",
    "        self.dataset = np.array(self.dataset)\n",
    "        self.categoryDict = dict(zip(self.target,categoryname))\n",
    "        self.target = np.array(self.target)\n",
    "        logging.info(\"The creation of the training data ran, with {} error(s), and has generated {} number(s) of training data\".format(error_count,data_count))\n",
    "        \n",
    "\n",
    "    def find_objects(self,input):\n",
    "        # TODO:\n",
    "        # This method takes an image as input and return the predicted class.\n",
    "        # This should be used in conjunction with the object tracking to identify\n",
    "        # What object is on the track.\n",
    "        pass\n",
    "\n",
    "    def __loadPretrainedModel(self):\n",
    "        # TODO:\n",
    "        # This method load a saved model, and is ment to be used when you don't want to \n",
    "        # retrain the model. \n",
    "        pass\n",
    "\n",
    "    def train_model(self,split=.25): \n",
    "        # Here we train the model, with our training data.\n",
    "        # Next we would like to save the model, such that we don't have to retrain everytime we \n",
    "        # Need to access the model.\n",
    "        X_train,X_test,y_train,y_test = train_test_split(self.dataset,self.target,test_size=split)\n",
    "        self.model = sk.svm.SVC(kernel='rbf',gamma='scale',C=1)\n",
    "        self.model.fit(X_train,y_train)\n",
    "        y_pred = self.model.predict(X_test)\n",
    "        print(\"The training score -rbf: {:.2f}\".format(self.model.score(X_train,y_train)))\n",
    "        print(\"The test score -rbf: {:.2f}\".format(self.model.score(X_test,y_test)))\n",
    "   \n",
    "    def __getimage(self,path):\n",
    "        # read the image using opencv\n",
    "        img = cv2.imread(path)\n",
    "        if(img is None):\n",
    "            return 0,0\n",
    "        else:\n",
    "            # convert into grayscal <- (might be discussed if we want to preserve the colors or not)\n",
    "            gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "            # resize the image to 80 x 80\n",
    "            return cv2.resize(gray,(80,80)), 1\n",
    "    \n",
    "    def __makefeatures(self,img):\n",
    "        # This method takes the image, and flattens it. \n",
    "        # It is also possible here to append some extra feature descriptors like:\n",
    "        # The histogram of oriented gradients (HOG), Edge images and many others.\n",
    "        # This can improve accuracy, but also adds to the feature space/dimentionality\n",
    "        features = []\n",
    "        # First we flatten the image\n",
    "        flatten = img.flatten()\n",
    "        # Some other features\n",
    "        more_features = []\n",
    "        # horizontal stack them\n",
    "        features = np.hstack((flatten,more_features))\n",
    "\n",
    "        # Use pca to reduce dimentionality\n",
    "        # TODO make this, i think it could be nice\n",
    "\n",
    "        return features\n",
    "if __name__ == \"__main__\":\n",
    "    t = TrackObjects()\n",
    "    t.createTrainingData()\n",
    "    print(t.dataset.shape)\n",
    "    print(t.target.shape)\n",
    "    print(t.target)\n",
    "    print(t.categoryDict)\n",
    "    t.train_model()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
